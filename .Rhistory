pred.params.div[1,5]<-round(preds.div$se.fit,1)
plt_name=paste(run_date, div.name, sep= " ")
fitFigName<- paste(div.name, ".png", sep='')
# Plot Big Wood at Hailey modeled data for visual evaluation
png(filename = file.path(fig_dir_mo, fitFigName),
width = 5.5, height = 5.5,units = "in", pointsize = 12,
bg = "white", res = 600)
plot(model$pred$obs, model$pred$pred, pch=19, xlab="Observed", ylab="Predicted", main=plt_name)
abline(0,1,col="gray50",lty=1)
dev.off()
return(list(pred.params.div, mod_sum$vars)) # is there something else we need here?
}
# initialize arrays to store output
div_mod_out <-data.frame(array(NA,c(length(div.names),5)))
rownames(div_mod_out)<- div.names
colnames(div_mod_out)<- c("Adj R2", "LOOCV R2", "RMSE", "Diversion", "+/-")
div_vars <-vector(mode = "list", length = length(div.names))
for (i in 1:length(div.names)) {
mod_out<- mod_div(div.names[i])
div_mod_out[div.names[i],]<- mod_out[[1]]
div_vars[i]<- mod_out[2]
}
# -----------------Water Right Curtailment Models -----------------------------#
basins<-unique(curtailments$subbasin)
wr_cat<- unique(curtailments$water_right_cat)
curtNames<-expand.grid(basins, wr_cat, stringsAsFactors = FALSE)
# function to develop model and predict curtailment dates for each water right
mod_dev<- function(water_right, subws){
pred.params.curt <-array(NA,c(1,6))
fitFigName<- paste(subws, water_right, ".png", sep='')
curt_sub<- curtailments %>% dplyr::select(-c(water_right_date,shut_off_date)) %>%
subset(water_right_cat == water_right) %>% subset(subbasin == subws) %>% dplyr::select(-c(subbasin, water_right_cat, wr_name))
curt <- var %>% dplyr::select(year, all_of(vol_cols),all_of(wq_cols), all_of(swe_cols),all_of(wint_t_cols)) %>%
inner_join(curt_sub, by = 'year') %>% filter(complete.cases(.))
#use regsubsets to assess the results
tryCatch({regsubsets.out<-regsubsets(shut_off_julian~., data=curt[,-c(1)], nbest=1, nvmax=4)},
error= function(e) {print(c("Curtailment model did not work", subws))}) #error catch
reg_sum<- summary(regsubsets.out)
rm(regsubsets.out)
vars<-reg_sum$which[which.min(reg_sum$bic),]
mod_sum<-list(vars = names(vars)[vars==TRUE][-1], adjr2 = reg_sum$adjr2[which.min(reg_sum$bic)], bic=reg_sum$bic[which.min(reg_sum$bic)])
#fit the regression model and use LOOCV to evaluate performance
form<- paste("shut_off_julian~ ", paste(mod_sum$vars, collapse=" + "), sep = "")
mod<-lm(form, data=curt)
mod_sum$lm<-summary(mod)$adj.r.squared
#save summary of LOOCV
model <- train(as.formula(form), data = curt, method = "lm", trControl = ctrl)
mod_sum$loocv<- model$results
# Prediction Data
pred.dat<-var[var$year == pred.yr,] %>% dplyr::select(mod_sum$vars)
div.vars<- match(div.names, mod_sum$vars)
#if predicted flows are in the model, add them here
if (length(grep('vol', mod_sum$vars)) > 0){
pred.var<- mod_sum$vars[grep('vol', mod_sum$vars)]
pred.dat[pred.var]<- pred.vols[pred.var]
}
if (length(div.vars[!is.na(div.vars)])>0){
pred.div<- mod_sum$vars[div.vars[!is.na(div.vars)]]
pred.dat[pred.div]<- div_mod_out[pred.div, "Diversion"]
}
# Model output
preds.curt<-predict(mod,newdata=pred.dat,se.fit=T,interval="prediction",level=0.95)
pred.params.curt[1,1]<-round(summary(mod)$adj.r.squared,2)
pred.params.curt[1,2]<-round(mod_sum$loocv$Rsquared,2)
pred.params.curt[1,3]<-round(mod_sum$loocv$RMSE)
pred.params.curt[1,4]<-round(preds.curt$fit[1])
pred.params.curt[1,5]<-round(preds.curt$se.fit,1)
pred.params.curt[1,6]<-round(preds.curt$fit[2])
# Make the max prediction doy 275
if (pred.params.curt[1,4] > 275){pred.params.curt[1,4] =275}
model$pred$pred[model$pred$pred > 275] = 275
plt_name=paste(run_date, subws, water_right, sep= " ")
# Plot  modeled data for visual evaluation
png(filename = file.path(fig_dir_mo, fitFigName),
width = 5.5, height = 5.5,units = "in", pointsize = 12,
bg = "white", res = 600)
plot(model$pred$obs, model$pred$pred, pch=19, xlab="Observed", ylab="Predicted", main=plt_name)
abline(0,1,col="gray50",lty=1)
dev.off()
return(list(pred.params.curt, mod_sum$vars)) # is there something else we need here?
}
# initialize arrays to store output
wr_mod_out <-data.frame(array(NA,c(9,6)))
rownames(wr_mod_out)<- paste(key[,1], key[,2], sep="")
colnames(wr_mod_out)<- c("Adj R2", "LOOCV R2", "RMSE", "Curt Day", "Day +/-", "Lower Curt")
wr_vars <-vector(mode = "list", length = 9)
names(wr_vars)<- paste(key[,1], key[,2], sep="")
# run all water rights through model dev and prediction function
for(i in 1:dim(key)[1]){
wr_name<- paste(key[i,1], key[i,2], sep="")
mod_out<- mod_dev(key[i,2], key[i,1])
wr_mod_out[wr_name,]<- mod_out[[1]]
wr_vars[wr_name]<- mod_out[2]
}
# Silver Creek A only has two values 9/31 and 10/1 - the model isn't that useful
# Save model fit output
png(file.path(fig_dir_mo,"r2s_wr.png"), height = 25*nrow(wr_mod_out), width = 80*ncol(wr_mod_out))
grid.table(wr_mod_out[,1:3])
dev.off()
# Save model parameters
list.save(wr_vars, file.path(fig_dir_mo, wr_params))
# Curtailment Summary ------
# couldnt get pivot wider to work ...
# tst<-pivot_wider(curtailments, names_from = c(subbasin, water_right_cat), values_from = shut_off_julian)
julian_curt<- data.frame(matrix(ncol = 10, nrow = length(min(curtailments$year):max(curtailments$year))))
colnames(julian_curt)<- c("year", "bw_ab_magicA", "bw_ab_magicB", "bw_ab_magicC", "bw_bl_magicA", "bw_bl_magicB", "bw_bl_magicC", "sc_lwA",  "sc_lwB", "sc_lwC")
julian_curt$year <- min(curtailments$year):max(curtailments$year)
julian_curt$bw_ab_magicA <- curtailments %>% subset(water_right_cat =="A") %>% subset(subbasin == 'bw_ab_magic') %>% dplyr::select(shut_off_julian)
julian_curt$bw_ab_magicB <- curtailments %>% subset(water_right_cat =="B") %>% subset(subbasin == 'bw_ab_magic') %>% dplyr::select(shut_off_julian)
julian_curt$bw_ab_magicC <- curtailments %>% subset(water_right_cat =="C") %>% subset(subbasin == 'bw_ab_magic') %>% dplyr::select(shut_off_julian)
julian_curt$bw_bl_magicA <- curtailments %>% subset(water_right_cat =="A") %>% subset(subbasin == 'bw_bl_magic') %>% dplyr::select(shut_off_julian)
julian_curt$bw_bl_magicB <- curtailments %>% subset(water_right_cat =="B") %>% subset(subbasin == 'bw_bl_magic') %>% dplyr::select(shut_off_julian)
julian_curt$bw_bl_magicC <- curtailments %>% subset(water_right_cat =="C") %>% subset(subbasin == 'bw_bl_magic') %>% dplyr::select(shut_off_julian)
julian_curt$sc_lwA<- curtailments %>% subset(water_right_cat =="A") %>% subset(subbasin == 'sc_lw') %>% dplyr::select(shut_off_julian)
julian_curt$sc_lwB <- curtailments %>% subset(water_right_cat =="B") %>% subset(subbasin == 'sc_lw') %>% dplyr::select(shut_off_julian)
julian_curt$sc_lwC <- curtailments %>% subset(water_right_cat =="C") %>% subset(subbasin == 'sc_lw') %>% dplyr::select(shut_off_julian)
# Curtailment Correlations ------
# calculate correlations between locations
curt.cor.mat<-cor(julian_curt[-1], use="pairwise.complete")
# make the water rights model output same order
wr_out<- wr_mod_out[match(rownames(curt.cor.mat), rownames(wr_mod_out)),]
# create covariance matrix by multiplying by each models standard error
curt.outer.prod<-as.matrix(wr_out[,5])%*%t(as.matrix(wr_out[,5]))
curt.cov.mat<-curt.cor.mat*curt.outer.prod
# Draw curtailment dates using multivariate normal distribution
curt.sample<-data.frame(mvrnorm(n=5000,mu=(as.matrix(wr_out[,4])),Sigma=curt.cov.mat))
curt.sample[curt.sample>275] = 275
colnames(curt.sample)<-c("Big Wood abv Magic '83", "Big Wood abv Magic '84", "Big Wood abv Magic '86", "Big Wood blw Magic '83", "Big Wood blw Magic '84", "Big Wood blw Magic '86", "Silver Creek '83",  "Silver Creek '84", "Silver Creek '86")
write.csv(curt.sample, file.path(model_out,"curt.sample.csv"),row.names=F)
# Plot boxplots of predicted curtailment dates from each model
curt.samp.fig<- curt.sample %>% pivot_longer(everything(),  names_to = "site", values_to = "value")
curt.samp.fig$yr<-as.factor(rep(c(1983, 1984, 1986),15000))
#curt.samp.fig$loc<-rep(c(1,4,7,2,5,8,3,6,9),5000)
cs<- ggplot(curt.samp.fig,
aes(x=site, y=as.Date(value, origin=as.Date(paste(pred.yr,"-01-01",sep=""))), fill=yr)) +
theme_bw()+
geom_boxplot() +
scale_fill_viridis(discrete = TRUE, alpha=0.6) +
scale_y_date(date_breaks = "1 week", date_labels = "%b %d")+
scale_x_discrete(labels = wrap_format(10)) +
theme(legend.position="none") +
ggtitle("Sampled Curtailment Dates") +
xlab("")+
ylab("Curtailment Date")
png(filename = file.path(fig_dir_mo,"sampled_curtailments.png"),
width = 6.5, height = 5.5,units = "in", pointsize = 12,
bg = "white", res = 600)
print(cs)
dev.off()
curt_hist<- ggplot(curtailments,
aes(x=wr_name, y=as.Date(shut_off_julian, origin=as.Date(paste(pred.yr,"-01-01",sep=""))), fill=water_right_cat))+
theme_bw()+
geom_boxplot()+
geom_jitter(alpha=0.6)+
scale_fill_viridis(discrete = TRUE, alpha=0.4) +
scale_y_date(date_breaks = "1 week", date_labels = "%b %d")+
scale_x_discrete(labels = wrap_format(10))  +
ggtitle("Historic Curtailment Dates") +
theme(legend.position="none") +
xlab("")+
ylab("Curtailment Date")
png(filename = file.path(fig_dir_mo,"hist_curtailments.png"),
width = 6.5, height = 5.5,units = "in", pointsize = 12,
bg = "white", res = 600)
print(curt_hist)
dev.off()
# change from day of year to date for the table
wr_tbl<-wr_out[,4:5]
wr_tbl[,1]<- as.Date(wr_tbl[,1], origin=as.Date(paste(pred.yr,"-01-01",sep="")), format='%m/%d')
rownames(wr_tbl)<- c('Big Wood Above Magic 3-24-83', 'Big Wood Above Magic 10-14-84', 'Big Wood Above Magic 6-01-86', 'Big Wood Below Magic 83',  'Big Wood Below Magic 84', 'Big Wood Below Magic 86', 'Silver Creek 83', 'Silver Creek 84', 'Silver Creek 86')
png(file.path(fig_dir_mo,"wr_preds.png"), height = 25*nrow(wr_mod_out), width = 80*ncol(wr_mod_out))
grid.table(wr_tbl)
dev.off()
# Draw curtailment dates using multivariate normal distribution
curt.sample<-data.frame(mvrnorm(n=5000,mu=(as.matrix(wr_out[,4])),Sigma=curt.cov.mat))
wr_out[,4]
curt.outer.prod
wr_out
data_dir
bwh.flow.simLong<- read.csv(file.path(model_out, "BWB.sim.csv")) %>% pivot_longer(cols = -c(1), names_to = "simulation", values_to = "dailyFlow")
bws.flow.simLong<- read.csv(file.path(model_out, "BWS.sim.csv")) %>% pivot_longer(cols = -c(1), names_to = "simulation", values_to = "dailyFlow")
cc.flow.simLong<- read.csv(file.path(model_out, "CC.sim.csv")) %>% pivot_longer(cols = -c(1), names_to = "simulation", values_to = "dailyFlow")
sc.flow.simLong <- read.csv(file.path(model_out, "SC.sim.csv")) %>% pivot_longer(cols = -c(1), names_to = "simulation", values_to = "dailyFlow")
write.csv(bwh.flow.simLong, file.path(data_dir,'bwh.flow.simLong.csv'), row.names=FALSE)
write.csv(bws.flow.simLong, file.path(data_dir,'bws.flow.simLong.csv'), row.names=FALSE)
write.csv(cc.flow.simLong, file.path(data_dir,'cc.flow.simLong.csv'), row.names=FALSE)
write.csv(sc.flow.simLong, file.path(data_dir,'sc.flow.simLong.csv'), row.names=FALSE)
```{r setup, include=FALSE}
params_list2 = list(git_dir = git_dir, cd=cd)
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
# GitHub File Path
git_dir <<- '~/github/LuckyPeakPower'
# Local File Path
cd <<- '~/Desktop/LuckyPeak'
# Data Directory
data_dir <<- file.path(cd, 'data')
# Data folders
flow_dir<<-file.path(data_dir, 'daily water report July') #will update when new water reports are complete
revenue_dir <<- file.path(data_dir, 'GenerationReports')
gen_dir <<- file.path(data_dir,'LP historical')
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
endDate <<- Sys.Date()-1
# Date Range to show in Monthly Report
# to enter a custom time range replace after '<<-' with as.Date("YYYY-MM-DD")
start_table <<- as.Date("2022-06-01") #floor_date(endDate)
end_table <<- as.Date("2022-06-30") #endDate
# GitHub File Path
git_dir <<- '~/github/LuckyPeakPower'
# Local File Path
cd <<- '~/Desktop/LuckyPeak'
# Data Directory
data_dir <<- file.path(cd, 'data')
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
knitr::opts_chunk$set(echo = FALSE, fig.pos = "H")
library(knitr)
library(kableExtra)
library(lubridate)
library(tidyverse)
# Directories
fig_dir <<- './figures'
data_dir <<- file.path(params$cd, 'data')
endDate <<- Sys.Date() -2
emo<- month(endDate)
eda<- day(endDate)
mm2inches<-  0.0393701 #(from mm to inches)
# Import Data
#p_mean<- read.csv(file.path(data_dir,'p_mean.csv'))
snotel_data<-read.csv(file.path(data_dir,'snotel_data.csv'))
res <- read.csv(file.path(data_dir,'reservoir_data.csv'))
lp_gen_flow_daily <- read.csv(file.path(data_dir,'lp_gen_flow_daily.csv')) #MW
pred_tot_gen<- read.csv(file.path(data_dir,"pred_tot_gen.csv"), row.names = 1) %>% `colnames<-` ("12 month generation (MWh)")#read in as 12 month total MWH
p_mean<- read.csv(file.path(data_dir,'p_mean.csv')) %>% dplyr::select(5,3,2,4) %>% `colnames<-` (c('Month', 'YTD Precip(in)', 'Average Precip (in)', '% Average'))
#Lucky Peak 264400, Anderson 413100; Arrowrock 272200; from hydromet
res_max_stor <- c(264400, 413100, 272200)
# Pull current SWE conditions and compare to historic
swe_today<- snotel_data %>% filter(mo==emo & day== eda)
p_med<- swe_today %>% filter(date < endDate-1) %>% group_by(site_name) %>% dplyr::summarise(med_swe = round(median(snow_water_equivalent, na.rm = TRUE), 0), med_p = round(median(precipitation_cumulative, na.rm = TRUE) *mm2inches, 0))
p_cur<- swe_today %>% filter(date == endDate) %>% dplyr::select(site_name, swe_cur = snow_water_equivalent, p_cum = precipitation_cumulative)
p_cur[,2:3]<- round(p_cur[,2:3]*mm2inches, 0)
p_info<- merge(p_med, p_cur, by= "site_name")
p_info$per_swe<- round(p_info$swe_cur/ p_info$med_swe,2)*100
p_info$per_p<- round(p_info$p_cum/ p_info$med_p,2)*100
p_info<-p_info %>% dplyr::select(site_name, swe_cur, med_swe, per_swe, p_cum, med_p, per_p)
colnames(p_info)<- c('Site','Todays SWE', 'Median SWE','% Median', 'YTD Precip', 'Median YTD Precip', '% Median')
p_meds<- c("Basin Median", round(apply(p_info[2:7], 2, median),0))
p_info<- rbind(p_info, p_meds)
# Summarize Reservoir Storage (af and id (computed inflow))
res_today<- res %>% filter(mo==emo & day== eda)
res_means<- res_today %>% filter(DateTime < endDate-1) %>%
summarise_at(c("luc_af", "and_af", "ark_af", "luc_id", "ark_id", "brfi_qd", "mori_qd", 'arki_qd'), mean, na.rm = TRUE) %>% round(0)
res_cur<- res_today %>% filter(DateTime == endDate) %>% dplyr::select("luc_af", "and_af", "ark_af", "luc_id", "ark_id", "brfi_qd", "mori_qd", 'arki_qd') %>% round(0)
inflow_cur<- c(res_cur[4], res_cur[6],res_cur[5],res_cur[8],res_cur[7])%>% as.data.frame()
inflow_mean<- c(res_means[4], res_means[6],res_means[5], res_means[8], res_means[7])%>% as.data.frame()
inflow_per_mean <- t(round(inflow_cur/inflow_mean*100, 0))
inflow_cur
inflow_mean
flow_dir<<-file.path(data_dir, 'daily water report July') #will update when new water reports are complete
revenue_dir <<- file.path(data_dir, 'GenerationReports')
gen_dir <<- file.path(data_dir,'LP historical')
# ------------------------------------------------------------------------------
# Power plant management details
# ------------------------------------------------------------------------------
# number of days you anticipate having generators down in the forecasting period
down_time<<- NA
#TODO: subtract days of generators being offline during forecasting period from forecast arima script
#g.131 <<- NA
#g.132 <<- NA
#g.133 <<- NA
# ------------------------------------------------------------------------------
# Run scripts to download and analyze data, and run forecasting model
# ------------------------------------------------------------------------------
source(file.path(git_dir, 'grabHydromet.R'))
source(file.path(git_dir, 'packages.R'))
source(file.path(git_dir, 'data_download.R')) # downloads online data
source(file.path(git_dir, 'import_LPdata.R')) # automated internal data
source(file.path(git_dir, 'hist_data_clean.R')) # cleans up historic monthly data sheets
source(file.path(git_dir, 'hist_flow_precip_analysis.R'))
source(file.path(git_dir,'forecast_arima.R'))
#merge flow and generation data
lp_mo_flow_gen<-merge(mo_gen, luc_mo, by= c("mo", "year", "date"))
View(lp_mo_flow_gen)
write.csv(lp_mo_flow_gen, file.path(data_dir,'mo_streamflow_gen.csv'), row.names = FALSE)
source(file.path(git_dir,'forecast_arima.R'))
params_list2 = list(git_dir = git_dir, cd=cd)
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
endDate <<- Sys.Date()-1
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
View(fc_3mo)
# Forecast Length in months (e.g. 12 = the next 12 months)
m<<- 12
endDate <<- Sys.Date()-1
# Date Range to show in Monthly Report
# to enter a custom time range replace after '<<-' with as.Date("YYYY-MM-DD")
start_table <<- as.Date("2022-06-01") #floor_date(endDate)
end_table <<- as.Date("2022-06-30") #endDate
# GitHub File Path
git_dir <<- '~/github/LuckyPeakPower'
# git_dir <<-'C:/Users/dyet/Desktop/Gitrepo/LuckyPeakPower-main'
# Local File Path
cd <<- '~/Desktop/LuckyPeak'
# cd <<- 'C:/Users/dyet/Desktop/Gitrepo'
# Data Directory
data_dir <<- file.path(cd, 'data')
# Data folders
flow_dir<<-file.path(data_dir, 'daily water report July') #will update when new water reports are complete
revenue_dir <<- file.path(data_dir, 'GenerationReports')
gen_dir <<- file.path(data_dir,'LP historical')
# ------------------------------------------------------------------------------
# Power plant management details
# ------------------------------------------------------------------------------
# number of days you anticipate having generators down in the forecasting period
down_time<<- NA
#TODO: subtract days of generators being offline during forecasting period from forecast arima script
#g.131 <<- NA
#g.132 <<- NA
#g.133 <<- NA
# ------------------------------------------------------------------------------
# Run scripts to download and analyze data, and run forecasting model
# ------------------------------------------------------------------------------
source(file.path(git_dir, 'grabHydromet.R'))
source(file.path(git_dir, 'packages.R'))
source(file.path(git_dir, 'data_download.R')) # downloads online data
source(file.path(git_dir, 'import_LPdata.R')) # automated internal data
source(file.path(git_dir, 'hist_data_clean.R')) # cleans up historic monthly data sheets
source(file.path(git_dir, 'hist_flow_precip_analysis.R'))
source(file.path(git_dir,'forecast_arima.R'))
# ------------------------------------------------------------------------------
# Compile Figures and Forecasts into a pdf
# ------------------------------------------------------------------------------
endDate <<- Sys.Date()-1
params_list = list(git_dir = git_dir, cd=cd, start_table=start_table, end_table=end_table)
rmarkdown::render(file.path(git_dir, 'MonthlyGenReport.Rmd'), envir = new.env(), params = params_list,
output_file = file.path(git_dir, paste0("LP_MonthlyReport-", endDate, ".pdf")))
params_list2 = list(git_dir = git_dir, cd=cd)
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
source(file.path(git_dir, 'hist_data_clean.R')) # cleans up historic monthly data sheets
length(fns) > 0
any(updated)
exists("lp_gen_flow_daily_new")
source(file.path(git_dir, 'hist_data_clean.R')) # cleans up historic monthly data sheets
#-------------------------------------------------------------------------------
# plot relationships between head, flow, generation and efficiency
#-------------------------------------------------------------------------------
#plotting generation has a cleaner relationship and highlights lower efficiency
plot_ly(lp_gen_flow_daily_updated[lp_gen_flow_daily_updated$g.133 > 0], x=~f.133, y=~head,
z=~g.133, color=~eff.133) %>%
add_markers(size=1)
View(lp_gen_flow_daily_updated)
plot_ly(lp_gen_flow_daily_updated[lp_gen_flow_daily_updated$g.133 > 0], x=~f.133, y=~head,
z=~g.133, color=~eff.133) %>%
add_markers(size=1)
#plotting generation has a cleaner relationship and highlights lower efficiency
plot_ly(data=lp_gen_flow_daily_updated[lp_gen_flow_daily_updated$g.133 > 0], x=~f.133, y=~head,
z=~g.133, color=~eff.133) %>%
add_markers(size=1)
# for the small generator, below 250 cfs and a head of 150 the generation and efficiency will drop
plot_ly(lp_gen_flow_daily_updated[lp_gen_flow_daily_updated$g.131 > 0], x=~f.131, y=~head,
z=~eff.131, color=~g.131) %>%
add_markers(size=1)
plot_ly(lp_gen_flow_daily_updated[lp_gen_flow_daily_updated$g.132 > 0], x=~f.132, y=~head,
z=~eff.132, color=~g.132) %>%
add_markers(size=1)
plot_ly(lp_gen_flow_daily[lp_gen_flow_daily$g.132 > 0], x=~f.132, y=~head,
z=~eff.132, color=~g.132) %>%
add_markers(size=1)
#-------------------------------------------------------------------------------
# plot relationships between head, flow, generation and efficiency
#-------------------------------------------------------------------------------
#plotting generation has a cleaner relationship and highlights lower efficiency
tst<- lp_gen_flow_daily_updated[lp_gen_flow_daily_updated$g.133 > 0]
#-------------------------------------------------------------------------------
# plot relationships between head, flow, generation and efficiency
#-------------------------------------------------------------------------------
#plotting generation has a cleaner relationship and highlights lower efficiency
tst<-
plot_ly(lp_gen_flow_daily_updated[lp_gen_flow_daily_updated$g.133 > 0,], x=~f.133, y=~head,
z=~g.133, color=~eff.133) %>%
add_markers(size=1)
#-------------------------------------------------------------------------------
# plot relationships between head, flow, generation and efficiency
#-------------------------------------------------------------------------------
#plotting generation has a cleaner relationship and highlights lower efficiency
plot_ly(lp_gen_flow_daily_updated[lp_gen_flow_daily_updated$g.133 > 0,], x=~f.133, y=~head,
z=~g.133, color=~eff.133) %>%
add_markers(size=1)
source(file.path(git_dir, 'hist_data_clean.R')) # cleans up historic monthly data sheets
source(file.path(git_dir, 'hist_flow_precip_analysis.R'))
source(file.path(git_dir,'forecast_arima.R'))
endDate <<- Sys.Date()-1
params_list = list(git_dir = git_dir, cd=cd, start_table=start_table, end_table=end_table)
rmarkdown::render(file.path(git_dir, 'MonthlyGenReport.Rmd'), envir = new.env(), params = params_list,
output_file = file.path(git_dir, paste0("LP_MonthlyReport-", endDate, ".pdf")))
params_list2 = list(git_dir = git_dir, cd=cd)
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
View(res_fin)
res_sum
rownames(res_sum)
rownames(res_fin)
res_cur
res_means
sum(res_means[1:3])
sum(res_cur[1:3])
511822/481666
res_max_stor
sum(res_max_stor)
511822/949700
481666/949700
knitr::opts_chunk$set(echo = FALSE)
options(kableExtra.latex.load_packages = FALSE)
library(knitr)
library(kableExtra)
library(lubridate)
library(tidyverse)
options(knitr.table.format = "latex")
# Directories
fig_dir <<- './figures'
data_dir <<- file.path(params$cd, 'data')
endDate <<- Sys.Date() -1
emo<- month(endDate)
eda<- day(endDate)
basin_per<- round(c(res_cur[1:3]/949700, res_means[1:3]/949700, res_cur[1:3]/res_means[1:3]) *100, 2)
c(res_cur[1:3]/949700, res_means[1:3]/949700, res_cur[1:3]/res_means[1:3])
round(c(sum(res_cur[1:3])/949700, sum(res_means[1:3])/949700, sum(res_cur[1:3])/sum(res_means[1:3])) *100, 2)
basin_per<- round(c(sum(res_cur[1:3])/949700, sum(res_means[1:3])/949700, sum(res_cur[1:3])/sum(res_means[1:3])) *100, 0)
basin_per<- round(c(sum(res_cur[1:3])/949700, sum(res_means[1:3])/949700, sum(res_cur[1:3])/sum(res_means[1:3])) *100, 0)
basin_per
View(mo_gen2)
View(mwh_quant)
View(pred_tot_gen)
write.csv(mwh_quant,file.path(data_dir,"mwh_quant.csv"))
write.csv(round(mwh_quant,0),file.path(data_dir,"mwh_quant.csv"))
knitr::opts_chunk$set(echo = FALSE, fig.pos = "H")
library(knitr)
library(kableExtra)
library(lubridate)
library(tidyverse)
# Directories
fig_dir <<- './figures'
data_dir <<- file.path(params$cd, 'data')
endDate <<- Sys.Date() -2
emo<- month(endDate)
eda<- day(endDate)
mm2inches<-  0.0393701 #(from mm to inches)
mwh_quant<- read.csv(file.path(data_dir,"mwh_quant.csv"), row.names = 1)
View(mwh_quant)
mwh_quant[2:4,]
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
rmarkdown::render(file.path(git_dir, 'PowerBrokerReport.Rmd'), params = params_list2,
output_file = file.path(git_dir, paste0("LP_12moForecast-", endDate, ".pdf")))
library(readxl)
setwd("/Users/kendrakaiser/github/StreamflowCatalog")
#USFS Region 6 stream
catalog<- read_excel("data/Streamflow_Catalog.xlsx")
View(catalog)
#USFS Region 6 stream
catalog<- read_excel("data/Streamflow_Catalog.xlsx")
ID_cont <- catalog %>% (meas.freq == 'continuous')
library(tidyverse)
ID_cont <- catalog %>% (meas.freq == 'continuous')
View(catalog)
ID_cont <- catalog %>% select(meas.freq == 'continuous')
colnames(catalog)
ID_cont <- catalog %>% select(meas.freq)
ID_cont <- catalog %>% filter(meas.freq  == 'continuous')
View(ID_cont)
ID_cont <- catalog %>% filter(meas.freq  == 'continuous') %>% filter(state = "Idaho")
ID_cont <- catalog %>% filter(meas.freq  == 'continuous') %>% filter(state == "Idaho")
unique_co<- unique(catalog$county)
unique_co
cat_new<- catalog %>% filter(organization != "USGS")
View(cat_new)
cat_new<- catalog %>% filter(organization != "United States Geological Survey")
cont<- cat_new  %>% filter(meas.freq  == 'continuous')
unique(catalog$meas.freq )
cont<- cat_new  %>% filter(meas.freq  == 'continuous')
syn<- cat_new  %>% filter(meas.freq  == 'synoptic')
seas<- cat_new  %>% filter(meas.freq  == 'seasonal')
unk<- cat_new  %>% filter(meas.freq  == 'unknown')
naa<-unk<- cat_new  %>% filter(meas.freq  == 'NA')
unk<- cat_new  %>% filter(meas.freq  == 'unknown')
naa<- cat_new  %>% filter(meas.freq  == 'NA')
View(seas)
View(naa)
View(cat_new)
nastart<-is.na(cat_new$start)
nastart<-sum(is.na(cat_new$start))
naend<-sum(is.na(cat_new$end))
1146+1164
2310/20698
sum(is.na(cat_new$url))
19507/20698
sum(is.na(cont$url))
1647/2751
1-.598
